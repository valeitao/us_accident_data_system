{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Star Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Corrigir import do star schema\n",
    "url = 'https://i.imgur.com/1prxQ4H.png'\n",
    "response = requests.get(url, stream=True)\n",
    "img = Image.open(response.raw)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação dos datasets relevantes ao problema\n",
    "\n",
    "Datasets a importar:\n",
    "* US Accidents\n",
    "* TMC's e eventos associados\n",
    "* Calendário com fases da lua (\\*)\n",
    "* Limite máximo de velocidade por estado\n",
    "* Dados de consumo de álcool por estado\n",
    "* Quantidade de automóveis registados por estado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importação do dataset US Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import us accidents dataset\n",
    "us_acidents = pd.read_csv('US_Accidents_Dec19.csv')\n",
    "us_acidents[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importação do dataset relativo a TMCs / Criação da Dimensão TMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import event codes\n",
    "event_code = pd.read_csv('event_code_tmc.csv', delimiter=';')\n",
    "event_code = event_code.rename(columns={\"Code\": \"TMC_Key\", \"Description\":\"Event\"})\n",
    "\n",
    "# add out-of-range key\n",
    "event_code = event_code.append({'TMC_Key': -1, 'Event': 'unidentified'}, ignore_index=True)\n",
    "event_code[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importação do dataset sobre consumo de álcool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import alcohool consumption rates by state\n",
    "alcohol_consumption = pd.read_csv('alcohol_consumption_state.csv', delimiter=';')\n",
    "\n",
    "alcohol_consumption.at[20, \"State\"] = \"Massachusetts\"\n",
    "\n",
    "alcohol_consumption.loc[alcohol_consumption['rate'].apply(lambda x : x <= 2.0), 'discretizeRate'] = 'Low'\n",
    "alcohol_consumption.loc[alcohol_consumption['rate'].apply(lambda x : (x > 2.0) & (x <= 2.5)), 'discretizeRate'] = 'Medium'\n",
    "alcohol_consumption.loc[alcohol_consumption['rate'].apply(lambda x : (x > 2.5) & (x <= 3.5)), 'discretizeRate'] = 'High'\n",
    "alcohol_consumption.loc[alcohol_consumption['rate'].apply(lambda x : x > 3.5), 'discretizeRate'] = 'Very High'\n",
    "\n",
    "alcohol_consumption = alcohol_consumption.sort_values(by=['rate'], ascending=False)\n",
    "print(alcohol_consumption[:5])\n",
    "\n",
    "# Create dictionary where each key corresponds to a state' rate of alcoholism\n",
    "alcohol_dict = pd.Series(alcohol_consumption['discretizeRate'].values,index=alcohol_consumption['State']).to_dict()\n",
    "alcohol_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importação do dataset sobre registos automóveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import vehicle registrations by state\n",
    "vehicle_registration = pd.read_csv('vehicle_registrations_usa.csv',delimiter=';')\n",
    "vehicle_registration = vehicle_registration[vehicle_registration['State'] != 'Dist. of Col.'].reset_index(drop=True)\n",
    "\n",
    "vehicle_registration.at[4, \"State\"] = \"California\"\n",
    "vehicle_registration.at[6, \"State\"] = \"Connecticut\"\n",
    "\n",
    "\n",
    "for i in range(len(vehicle_registration.index)):\n",
    "    vehicle_registration.at[i, \"Total\"] = int(re.sub(' ', '', vehicle_registration.loc[i][\"Total\"]))\n",
    "\n",
    "vehicle_registration = vehicle_registration.sort_values(by=['Total'], ascending=False)\n",
    "\n",
    "vehicle_registration.loc[vehicle_registration['Total'].apply(lambda x : x <= 5000000), 'discretizeTotal'] = 'Low'\n",
    "vehicle_registration.loc[vehicle_registration['Total'].apply(lambda x : (x > 5000000) & (x <= 10000000)), 'discretizeTotal'] = 'Medium'\n",
    "vehicle_registration.loc[vehicle_registration['Total'].apply(lambda x : (x > 10000000) & (x <= 20000000)), 'discretizeTotal'] = 'High'\n",
    "vehicle_registration.loc[vehicle_registration['Total'].apply(lambda x : x > 20000000), 'discretizeTotal'] = 'Very High'\n",
    "\n",
    "print(vehicle_registration[:5])\n",
    "\n",
    "vehicle_dict = pd.Series(vehicle_registration['discretizeTotal'].values,index=vehicle_registration['State']).to_dict()\n",
    "vehicle_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importação do dataset sobre nível de urbanização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import rural/urban information about counties\n",
    "urban = pd.read_excel('NCHSURCodes2013.xlsx')\n",
    "\n",
    "# drop unwanted information\n",
    "urban = urban.drop(['State Abr.','CBSA title', 'CBSA 2012 pop', 'County 2012 pop'], axis=1)\n",
    "\n",
    "for i in range(len(urban.index)):\n",
    "    urban.at[i, \"County name\"] = re.sub(' County', '', urban.loc[i][\"County name\"])\n",
    "    \n",
    "urban_term = {1:'Large Central Metro',\n",
    "              2:'Large Fringe Metro',\n",
    "              3:'Medium Metro',\n",
    "              4:'Small Metro',\n",
    "              5:'Micropolitan',\n",
    "              6:'Non-Core'}\n",
    "\n",
    "urban[\"2013 code\"] = urban[\"2013 code\"].map(urban_term)\n",
    "\n",
    "urban[\"County name\"] = urban[\"County name\"].replace('DeSoto', 'De Soto')\n",
    "urban[\"County name\"] = urban[\"County name\"].replace('St. Lucie', 'Saint Lucie')\n",
    "urban[\"County name\"] = urban[\"County name\"].replace('DeKalb', 'Dekalb')\n",
    "\n",
    "\n",
    "urban_dict = pd.Series(urban['2013 code'].values,index=urban['County name']).to_dict()\n",
    "urban_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importação do dataset sobre limites de velocidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import maximal speed limits by state\n",
    "speed_limits = pd.read_excel('speed_limit_state.xlsx')\n",
    "speed_limits = speed_limits.drop(['Freeway (trucks)','Freeway (urban)','Divided (rural)','Undivided (rural)','Residential'], axis=1)\n",
    "\n",
    "speed_limits = speed_limits.rename(columns={\"State or territory\": \"State\", \"Freeway (rural)\":\"Max Speed Limit (mph)\"})\n",
    "\n",
    "# List of all the US States\n",
    "us_states_list = [\"Alabama\",\"Alaska\",\"Arizona\",\"Arkansas\",\"California\",\"Colorado\",\n",
    "  \"Connecticut\",\"Delaware\",\"Florida\",\"Georgia\",\"Hawaii\",\"Idaho\",\"Illinois\",\n",
    "  \"Indiana\",\"Iowa\",\"Kansas\",\"Kentucky\",\"Louisiana\",\"Maine\",\"Maryland\",\n",
    "  \"Massachusetts\",\"Michigan\",\"Minnesota\",\"Mississippi\",\"Missouri\",\"Montana\",\n",
    "  \"Nebraska\",\"Nevada\",\"New Hampshire\",\"New Jersey\",\"New Mexico\",\"New York\",\n",
    "  \"North Carolina\",\"North Dakota\",\"Ohio\",\"Oklahoma\",\"Oregon\",\"Pennsylvania\",\n",
    "  \"Rhode Island\",\"South Carolina\",\"South Dakota\",\"Tennessee\",\"Texas\",\"Utah\",\n",
    "  \"Vermont\",\"Virginia\",\"Washington\",\"West Virginia\",\"Wisconsin\",\"Wyoming\"]\n",
    "\n",
    "# Reformat all the rows in the dataset\n",
    "for i in range(len(speed_limits.index)):\n",
    "    if(not pd.isna(speed_limits.loc[i][\"State\"])):\n",
    "        speed_limits.at[i, \"State\"] = re.sub('[^a-z A-Z]+', '', speed_limits.loc[i][\"State\"])\n",
    "        speed_limits.at[i, \"State\"] = speed_limits.loc[i][\"State\"].replace('\\t','')\n",
    "    if(not pd.isna(speed_limits.loc[i][\"Max Speed Limit (mph)\"])):\n",
    "        speed_limits.at[i, \"Max Speed Limit (mph)\"] = re.sub('\\(.*', '', speed_limits.loc[i][\"Max Speed Limit (mph)\"])\n",
    "\n",
    "# Filter only the US States\n",
    "for i in range(len(speed_limits.index)):\n",
    "    if(speed_limits.loc[i][\"State\"] not in us_states_list):\n",
    "        speed_limits = speed_limits.drop(i)\n",
    "    \n",
    "# Reset the index\n",
    "speed_limits = speed_limits.reset_index(drop=True)\n",
    "\n",
    "speed_limits[\"Max Speed Limit (mph)\"] = speed_limits['Max Speed Limit (mph)'].apply(lambda x: (x[:-4])[-3:])\n",
    "speed_limits[\"Max Speed Limit (mph)\"] = speed_limits['Max Speed Limit (mph)'].apply(lambda x: int(x))\n",
    "speed_limits.at[36, \"Max Speed Limit (mph)\"] = 70\n",
    "\n",
    "speed_limits = speed_limits.sort_values(by=['Max Speed Limit (mph)'], ascending=False)\n",
    "\n",
    "speed_limits.loc[speed_limits['Max Speed Limit (mph)'].apply(lambda x : x < 70), 'DiscretizeSpeedLimit'] = 'Low'\n",
    "speed_limits.loc[speed_limits['Max Speed Limit (mph)'].apply(lambda x : (x >= 70) & (x < 80)), 'DiscretizeSpeedLimit'] = 'Medium'\n",
    "speed_limits.loc[speed_limits['Max Speed Limit (mph)'].apply(lambda x : (x >= 80)), 'DiscretizeSpeedLimit'] = 'High'\n",
    "\n",
    "speed_dict = pd.Series(speed_limits['DiscretizeSpeedLimit'].values,index=speed_limits['State']).to_dict()\n",
    "speed_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento do dataset original\n",
    "\n",
    "#### Tratamento de dados nulos/incompletos\n",
    "\n",
    "* As linhas que têm valores relativos ao twilight e período do dia vazios serão removidas; \n",
    "* As linhas que não têm informação relativa à cidade na qual o acidente ocorre também serão                removidas;\n",
    "* Os códigos TMC (Traffic Message Channel) que sejam nulos serão identificados com um número fora do domínio dos códigos existentes e não vão ser relevantes para possíveis interrogações;\n",
    "* Definição de valores para dados meteorológicos nulos será feita com base na média de valores em cada atributo, ao nível da cidade, na respetiva semana em que ocorreu o acidente (\\*);\n",
    "* O preenchimento de dados quem não contêm fuso horário será feito através da correspondência entre o estado onde o acidente ocorreu e o fuso horário no qual se encontra.\n",
    "\n",
    "#### Remoção de colunas\n",
    "* 'Source',\n",
    "* 'Start_Lat',\n",
    "* 'Country',\n",
    "* 'Start_Lng',\n",
    "* 'End_Lat',\n",
    "* 'End_Lng',\n",
    "* 'Description',\n",
    "* 'Number',\n",
    "* 'Side',\n",
    "* 'Zipcode',\n",
    "* 'Airport_Code',\n",
    "* 'Weather_Timestamp',\n",
    "* 'Pressure(in)', \n",
    "* 'Wind_Chill(F)'\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_acidents.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unuseful information/columns\n",
    "us_acidents = us_acidents.drop(['Source','Start_Lat','Country','Start_Lng','End_Lat','End_Lng','Description','Number','Side','Zipcode','Airport_Code','Weather_Timestamp', 'Pressure(in)', 'Wind_Chill(F)'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete rows with non avaliable values\n",
    "us_acidents = us_acidents.dropna(subset=['City', 'Civil_Twilight','Nautical_Twilight','Astronomical_Twilight']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace TMC values with out-of-range values, not used in OLAP.\n",
    "us_acidents['TMC'].fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace empty timezone values with the correspondent ones from each state\n",
    "timezone_df = us_acidents[[\"State\", \"Timezone\"]].drop_duplicates(subset=\"State\")\n",
    "timezone_dict = pd.Series(timezone_df['Timezone'].values,index=timezone_df['State']).to_dict()\n",
    "\n",
    "us_acidents['Timezone'].fillna(us_acidents['State'].map(timezone_dict), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### POI Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add POI_Key\n",
    "us_acidents.insert(us_acidents.columns.get_loc(\"Amenity\"), 'POI_Key', range(1, 1 + len(us_acidents)))\n",
    "us_acidents['POI_Key'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_dimension = us_acidents.loc[:,'POI_Key':'Turning_Loop'] # create poi dataset\n",
    "poi_dimension.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_dimension[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unwanted data from the us_acidents dataframe\n",
    "us_acidents = us_acidents.drop(['Amenity', 'Bump', 'Crossing', 'Give_Way', 'Junction', 'No_Exit', 'Railway', 'Roundabout', 'Station', 'Stop', 'Traffic_Calming', 'Traffic_Signal', 'Turning_Loop'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State of Accidents Dataset, now with POI_Key\n",
    "us_acidents.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Location Dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inserção de Chave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_acidents.insert(us_acidents.columns.get_loc(\"Street\"), 'LocationKey', range(1, 1 + len(us_acidents))) # add location_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Definição dos atributos de região"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_acidents['State'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar??\n",
    "# Muitos dados que temos não incluem este estado - Não é um estado\n",
    "print(us_acidents.loc[us_acidents[\"State\"] == 'DC'][\"State\"])\n",
    "us_acidents = us_acidents[us_acidents[\"State\"] != 'DC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_values = {'OH':'Ohio', 'WV':'West Virginia', 'CA': 'California', 'FL': 'Florida', 'GA': 'Georgia', 'SC':'South Carolina', 'NE': 'Nebraska', 'IA': 'Iowa', 'IL': 'Illinois', 'MO': 'Missouri', 'WI': 'Wisconsin',\n",
    "       'IN': 'Indiana', 'MI': 'Michigan', 'NJ': 'New Jersey', 'NY': 'New York', 'CT': 'Connecticut', 'MA': 'Massachusetts', 'RI': 'Rhode Island', 'NH': 'New Hampshire', 'PA': 'Pennsylvania', 'KY': 'Kentucky', 'MD': 'Maryland',\n",
    "       'VA': 'Virginia', 'DE': 'Delaware', 'TX':'Texas', 'WA': 'Washington', 'OR': 'Oregon', 'AL': 'Alabama', 'NC': 'North Carolina', 'MN': 'Minnesota', 'OK': 'Oklahoma', 'LA': 'Louisiana',\n",
    "   'TN': 'Tennessee', 'UT': 'Utah', 'CO': 'Colorado', 'AZ': 'Arizona', 'NV': 'Nevada', 'KS': 'Kansas', 'MS': 'Mississippi', 'NM': 'New Mexico', 'ME': 'Maine', 'AR': 'Arkansas', 'WY': 'Wyoming','VT': 'Vermont', 'ID': 'Idaho', 'ND': 'North Dakota', 'MT': 'Montana', 'SD': 'South Dakota'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_acidents = us_acidents.replace({\"State\": replace_values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://en.wikipedia.org/wiki/List_of_regions_of_the_United_States#Census_Bureau-designated_regions_and_divisions\n",
    "## define subregion\n",
    "def sub_region(state):\n",
    "    new_england = ['Connecticut', 'Maine', 'Massachusetts', 'New Hampshire', 'Rhode Island', 'Vermont']\n",
    "    mid_atlantic = ['New Jersey', 'New York','Pennsylvania']\n",
    "    east_north_central = ['Illinois', 'Indiana', 'Michigan', 'Ohio', 'Wisconsin']\n",
    "    west_north_central = ['Iowa','Kansas','Minnesota','Missouri','Nebraska','North Dakota','South Dakota']\n",
    "    south_atlantic = ['Delaware','Florida','Georgia','Maryland','North Carolina','South Carolina','Virginia','West Virginia']\n",
    "    east_south_central = ['Alabama','Kentucky','Mississippi','Tennessee']\n",
    "    west_south_central = ['Arkansas','Louisiana','Oklahoma','Texas']\n",
    "    mountain = ['Arizona','Colorado','Idaho','Montana','Nevada','New Mexico','Utah','Wyoming']\n",
    "    pacific = ['Alaska','California','Hawaii','Oregon','Washington']\n",
    "    if state in new_england:\n",
    "        return 'New England'\n",
    "    elif state in mid_atlantic:\n",
    "        return 'Mid Atlantic'\n",
    "    elif state in east_north_central:\n",
    "        return 'East North Central'\n",
    "    elif state in west_north_central:\n",
    "        return 'West North Central'\n",
    "    elif state in south_atlantic:\n",
    "        return 'South Atlantic'\n",
    "    elif state in east_south_central:\n",
    "        return 'East South Central'\n",
    "    elif state in west_south_central:\n",
    "        return 'West South Central'\n",
    "    elif state in mountain:\n",
    "        return 'Mountain'\n",
    "    elif state in pacific:\n",
    "        return 'Pacific'\n",
    "    else:\n",
    "        return 'algo de errado'\n",
    "\n",
    "#define region\n",
    "def region(state):\n",
    "    northeast = ['Connecticut', 'Maine', 'Massachusetts', 'New Hampshire', 'Rhode Island', 'Vermont', 'New Jersey', 'New York','Pennsylvania']\n",
    "    midwest = ['Illinois', 'Indiana', 'Michigan', 'Ohio', 'Wisconsin', 'Iowa','Kansas','Minnesota','Missouri','Nebraska','North Dakota','South Dakota']\n",
    "    south = ['Delaware','Florida','Georgia','Maryland','North Carolina','South Carolina','Virginia','District of Columbia','West Virginia', 'Alabama','Kentucky','Mississippi','Tennessee', 'Arkansas','Louisiana','Oklahoma','Texas']\n",
    "    west = ['Arizona','Colorado','Idaho','Montana','Nevada','New Mexico','Utah','Wyoming', 'Alaska','California','Hawaii','Oregon','Washington']\n",
    "    if state in northeast:\n",
    "        return 'Northeast'\n",
    "    elif state in midwest:\n",
    "        return 'Midwest'\n",
    "    elif state in south:\n",
    "        return 'South'\n",
    "    elif state in west:\n",
    "        return 'West'\n",
    "    else:\n",
    "        return 'algo de errado'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add Region\n",
    "us_acidents.insert(us_acidents.columns.get_loc(\"Timezone\"), 'Region', us_acidents['State'].apply(lambda x: region(x)))\n",
    "\n",
    "# add subregion\n",
    "us_acidents.insert(us_acidents.columns.get_loc(\"Timezone\"), 'Subregion', us_acidents['State'].apply(lambda x: sub_region(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inserção de atributo AlcoholConsumptionRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_acidents[\"AlcoholConsumptionRate\"] = us_acidents[\"State\"].map(alcohol_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_acidents['AlcoholConsumptionRate'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserção do atributo NumberVehicleRegistrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_acidents[\"VehicleRegistrations\"] = us_acidents[\"State\"].map(vehicle_dict)\n",
    "\n",
    "us_acidents['VehicleRegistrations'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserção do atributo UrbanRuralClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add Rate\n",
    "us_acidents[\"CountyUrbanRuralClass\"] = us_acidents[\"County\"].map(urban_dict)\n",
    "\n",
    "#~81000 rows dropped - Errors in County, only with manual correction allowed\n",
    "us_acidents = us_acidents[us_acidents[\"CountyUrbanRuralClass\"].notna()]\n",
    "\n",
    "us_acidents['CountyUrbanRuralClass'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserção do atributo MaximumSpeedLimit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_acidents[\"StateMaxSpeedLimit\"] = us_acidents[\"State\"].map(vehicle_dict)\n",
    "\n",
    "us_acidents['StateMaxSpeedLimit'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TBD:\n",
    "* MoonCalendar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Date Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to timestamp data \n",
    "us_acidents[\"Start_Time\"]= pd.to_datetime(us_acidents[\"Start_Time\"])\n",
    "\n",
    "# convert to timestamp data type\n",
    "us_acidents[\"End_Time\"]= pd.to_datetime(us_acidents[\"End_Time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_acidents.insert(us_acidents.columns.get_loc(\"Start_Time\"), 'date_Key', range(1, 1 + len(us_acidents))) # add date_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_acidents.insert(us_acidents.columns.get_loc(\"End_Time\"), 'StartDay', us_acidents['Start_Time'].apply(lambda x: x.day)) # add date_key\n",
    "us_acidents.insert(us_acidents.columns.get_loc(\"End_Time\"), 'StartMonth', us_acidents['Start_Time'].apply(lambda x: x.month_name())) # add date_key\n",
    "us_acidents.insert(us_acidents.columns.get_loc(\"End_Time\"), 'StartYear', us_acidents['Start_Time'].apply(lambda x: x.year)) # add date_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_acidents.insert(us_acidents.columns.get_loc(\"Distance(mi)\"), 'EndDay', us_acidents['End_Time'].apply(lambda x: x.day)) # add date_key\n",
    "us_acidents.insert(us_acidents.columns.get_loc(\"Distance(mi)\"), 'EndMonth', us_acidents['End_Time'].apply(lambda x: x.month_name())) # add date_key\n",
    "us_acidents.insert(us_acidents.columns.get_loc(\"Distance(mi)\"), 'EndYear', us_acidents['End_Time'].apply(lambda x: x.year)) # add date_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_acidents.insert(us_acidents.columns.get_loc(\"Distance(mi)\"), 'WorkDay', us_acidents['End_Time'].apply(lambda x: x.day_name())) # add WorkDay parcialmente concluído\n",
    "us_acidents.insert(us_acidents.columns.get_loc(\"Distance(mi)\"), 'DayofWeek', us_acidents['End_Time'].apply(lambda x: x.day_name())) # add DayofWeek\n",
    "us_acidents.insert(us_acidents.columns.get_loc(\"Distance(mi)\"), 'Holiday', range(1, 1 + len(us_acidents))) # add Holiday --->> Não concluído\n",
    "us_acidents.insert(us_acidents.columns.get_loc(\"Distance(mi)\"), 'SchoolBreak', range(1, 1 + len(us_acidents))) # add SchoolBreak --->> Não concluído\n",
    "us_acidents.insert(us_acidents.columns.get_loc(\"Distance(mi)\"), 'Quarter', us_acidents['End_Time'].apply(lambda x: x.quarter)) # add Quarter\n",
    "us_acidents.insert(us_acidents.columns.get_loc(\"Distance(mi)\"), 'WeekNumber', us_acidents['End_Time'].apply(lambda x: x.weekofyear)) # add WeekNumber\n",
    "us_acidents.insert(us_acidents.columns.get_loc(\"Distance(mi)\"), 'MoonCalendar', range(1, 1 + len(us_acidents))) # add MoonCalendar --->> Não concluído"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
